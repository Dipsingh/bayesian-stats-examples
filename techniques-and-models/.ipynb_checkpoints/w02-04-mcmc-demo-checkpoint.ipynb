{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chain Monte Carlo Demo\n",
    "\n",
    "This is a demo of estimating Posterior Probabilities for a simplified case where we can work out the problem analytically, and show that Metropolis-Hastings algorithm for estimating the posterior via simulation is indeed working and giving us the right answer.\n",
    "\n",
    "## Problem Definition\n",
    "\n",
    "Your sibling has a loaded coin that you know will come up heads about 70% of the time, and they come to you with a coin which you are not sure is loaded or fair, and they want to make a bet with you. Prior probability of it being a loaded coin is 60%. You flip it 5 times, getting 2 heads and 3 tails. What is the posterior probability that this is a loaded coin?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import comb\n",
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytical Solution\n",
    "\n",
    "* $\\theta$ = {fair, loaded}\n",
    "* prior P($\\theta$ = loaded) = 0.6\n",
    "* likelihood f(x|$\\theta$) ~ Binomial(n=5, p=0.7) if loaded, Binomial(n=5, p=0.5) if fair\n",
    "* posterior f($\\theta$|x) = $\\frac{f(x=2|\\theta)*f(\\theta)}{f(x)}$ by Bayes theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytically, P(θ=loaded|x=2): 0.38839\n",
      "Analytically, P(θ=fair  |x=2): 0.61161\n"
     ]
    }
   ],
   "source": [
    "prior_loaded = 0.6\n",
    "prior_fair = 1 - 0.6\n",
    "likelihood_if_fair = comb(5, 2) * (0.5)**5\n",
    "likelihood_if_loaded = comb(5, 2) * (0.7)**2 * (0.3)**3\n",
    "denom = (likelihood_if_fair * prior_fair) + (likelihood_if_loaded * prior_loaded)\n",
    "posterior_fair = (likelihood_if_fair * prior_fair) / denom\n",
    "posterior_loaded = (likelihood_if_loaded * prior_loaded) / denom\n",
    "print(\"Analytically, P(\\u03b8=loaded|x=2): {:.5f}\".format(posterior_loaded))\n",
    "print(\"Analytically, P(\\u03b8=fair  |x=2): {:.5f}\".format(posterior_fair))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Chain Monte Carlo Solution\n",
    "\n",
    "We will set up a Markov Chain whose equilibrium distribution has the posterior distribution computed above. The code below runs a Markov Chain Monte Carlo simulation using the Metropolis-Hastings algorithm on the posterior distribution of the dice being loaded.\n",
    "\n",
    "The Metropolis-Hastings algorithm works as follows:\n",
    "* select an initial value for $\\theta$ (either $\\theta_{LOADED}$ or $\\theta_{FAIR}$\n",
    "* For i = 1..m (where m is large)\n",
    "  * Draw candidate $\\theta^*$ from a proper distribution ~ q($\\theta^*$|$\\theta_{i-1}$)\n",
    "  * Compute $\\alpha$ = $\\frac{g(\\theta^*) / q(\\theta^*|\\theta_{i-1})}{g(\\theta_{i-1}) / q(\\theta_{i-1}|\\theta^*)}$\n",
    "  * If $\\alpha$ >= 1, accept candidate $\\theta^*$, i.e., set $\\theta_i$ <- $\\theta^*$\n",
    "  * If 0 <= $\\alpha$ <= 1, \n",
    "    * accept candidate $\\theta^*$ with probability $\\alpha$, i.e., set $\\theta_i$ <- $\\theta^*$\n",
    "    * reject $\\theta^*$ with probability (1 - $\\alpha$), i.e., set $\\theta_i$ <- $\\theta_{i-1}$\n",
    "  \n",
    "Since the decision to accept $\\theta^*$ depends on the previous state $\\theta_{i-1}$, this is a Markov chain.\n",
    "\n",
    "Here the function g($\\theta$) is the posterior probability, i.e.:\n",
    "\n",
    "g($\\theta^*$) = f(x=2|$\\theta^*$) * f($\\theta^*$)\n",
    "\n",
    "g($\\theta_{i-1}$) = f(x=2|$\\theta_{i-1}$) * f($\\theta_{i-1}$)\n",
    "\n",
    "and because the distribution q is deterministic, i.e. $\\theta$ can be in either of two states, the values of q are equal to 1. \n",
    "\n",
    "Hence, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if θ=loaded, α=0.63504\n",
      "if θ=fair,   α=1.57470\n"
     ]
    }
   ],
   "source": [
    "def get_alpha(state, likelihood_fair, prior_fair, likelihood_loaded, prior_loaded):\n",
    "    \"\"\" 0=fair, 1=loaded \"\"\"\n",
    "    if state == 1:\n",
    "        return (likelihood_loaded * prior_loaded) / (likelihood_fair * prior_fair)\n",
    "    else:\n",
    "        return (likelihood_fair * prior_fair) / (likelihood_loaded * prior_loaded)\n",
    "\n",
    "alpha = get_alpha(1, likelihood_if_fair, prior_fair, likelihood_if_loaded, prior_loaded)\n",
    "print(\"if \\u03b8=loaded, \\u03b1={:.5f}\".format(alpha))\n",
    "alpha = get_alpha(0, likelihood_if_fair, prior_fair, likelihood_if_loaded, prior_loaded)\n",
    "print(\"if \\u03b8=fair,   \\u03b1={:.5f}\".format(alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"w02-04-mcmc-demo-f01.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = []\n",
    "state = np.random.randint(low=0, high=2, size=1)[0]    # 0=fair, 1=loaded\n",
    "for i in range(int(1e4)):\n",
    "    proposed_state = 1 if state == 0 else 0\n",
    "    alpha = get_alpha(proposed_state, likelihood_if_fair, prior_fair, likelihood_if_loaded, prior_loaded)\n",
    "    if alpha >= 1:\n",
    "        thetas.append(proposed_state)\n",
    "    else:\n",
    "        if np.random.uniform(low=0, high=1) <= alpha:  # accept proposed with prob=alpha\n",
    "            thetas.append(proposed_state)\n",
    "        else:\n",
    "            thetas.append(state)\n",
    "            proposed_state = state\n",
    "    state = proposed_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Via Simulation, P(θ=loaded|x=2): 0.39200\n",
      "Via Simulation, P(θ=fair  |x=2): 0.60800\n"
     ]
    }
   ],
   "source": [
    "ind_loaded = np.array(thetas) == 1\n",
    "p_loaded = np.mean(ind_loaded)\n",
    "ind_fair = np.array(thetas) == 0\n",
    "p_fair = np.mean(ind_fair)\n",
    "print(\"Via Simulation, P(\\u03b8=loaded|x=2): {:.5f}\".format(p_loaded))\n",
    "print(\"Via Simulation, P(\\u03b8=fair  |x=2): {:.5f}\".format(p_fair))      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationery Distribution of Markov Chain\n",
    "\n",
    "These values are also the stationery distribution of the Markov Chain. By definition the stationery distribution $\\pi$ satisfies the condition:\n",
    "\n",
    "$$\\pi P = \\pi$$\n",
    "\n",
    "where P is the transition matrix. Replacing the values we obtained for $\\pi$ analytically and via simulation, we see that this equation holds true for both cases (within bounds of approximation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.365, 0.635],\n",
       "       [1.   , 0.   ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = np.array([[0.365, 0.635], [1, 0]])\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.609348, 0.390652])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_s = np.array([0.61520, 0.38480])\n",
    "pi_P = np.matmul(pi_s, P)\n",
    "pi_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.61162765, 0.38837235])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_a = np.array([0.61161, 0.38839])\n",
    "pi_P = np.matmul(pi_a, P)\n",
    "pi_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bayes)",
   "language": "python",
   "name": "bayes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
